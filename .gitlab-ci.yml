image: docker:24.0.2

services:
  - docker:dind

variables:
  DOCKER_HOST: tcp://docker:2375/
  DOCKER_TLS_CERTDIR: ""
  IMAGE_TAG: $CI_COMMIT_SHORT_SHA
  EC2_USER: ubuntu
  EC2_SSH_KEY: /tmp/deploy_key.pem
  UV_VERSION: 0.8.4
  PYTHON_VERSION: 3.11
  BASE_LAYER: bookworm-slim
  UV_CACHE_DIR: .uv-cache
  UV_SYSTEM_PYTHON: 1

stages:
  - precommit
  - test
  - build
  - deploy
  - deploy-docs

pre-commit:
  stage: precommit
  image: python:$PYTHON_VERSION
  script:
    - pip install pre-commit
    - pre-commit run --all-files
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "dev"
    - if: $CI_COMMIT_BRANCH == "hotfix"

pytest:
  stage: test
  image: ghcr.io/astral-sh/uv:$UV_VERSION-python$PYTHON_VERSION-$BASE_LAYER
  variables:
    PYTHONPATH: "$CI_PROJECT_DIR/src"
  cache:
    - key:
        files:
          - pyproject.toml
      paths:
        - $UV_CACHE_DIR
  script:
    - uv pip install ".[tests]" --system
    - pytest
  artifacts:
    paths:
      - /htmlcov/
  coverage: /TOTAL.*? (100(?:\.0+)?\%|[1-9]?\d(?:\.\d+)?\%)$/
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event"
    - if: $CI_COMMIT_BRANCH == "main"
    - if: $CI_COMMIT_BRANCH == "dev"
    - if: $CI_COMMIT_BRANCH == "hotfix"

build-dashlab-prod:
  stage: build
  only:
    - main
  before_script:
    - apk add --no-cache curl python3 py3-pip bash
    - pip install awscli
  script:
    # Configure AWS CLI
    - aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
    - aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
    - aws configure set default.region $AWS_DEFAULT_REGION

    # Login to ECR
    - aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_REGISTRY

    # Build Docker image
    - docker build --target runtime -f docker/Dockerfile -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .

    # Push to ECR
    - docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

deploy-to-ec2:
  stage: deploy
  only:
    - main
  before_script:
    - apk add --no-cache curl python3 py3-pip bash openssh-client rsync
    - pip install awscli
  script:
    - echo "$SSH_PRIVATE_KEY_B64" | base64 -d > $EC2_SSH_KEY
    - chmod 400 $EC2_SSH_KEY

    # Copy latest compose.prod.yml from repo to server
    - rsync -avz -e "ssh -o StrictHostKeyChecking=no -i $EC2_SSH_KEY" ./docker/compose.prod.yml $EC2_USER@$EC2_HOST:/home/ubuntu/compose.prod.yml

    - |
      ssh -o StrictHostKeyChecking=no -i $EC2_SSH_KEY $EC2_USER@$EC2_HOST << EOF
        export IMAGE="$ECR_REGISTRY/$ECR_REPOSITORY:$CI_COMMIT_SHORT_SHA"
        export AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION

        # Authenticate with ECR
        aws ecr get-login-password | docker login --username AWS --password-stdin $ECR_REGISTRY

        cd /home/ubuntu

        # Get all services except caddy (evaluated on EC2)
        SERVICES=\$(docker compose -f compose.prod.yml config --services | grep -v '^caddy$')

        echo "Pulling latest images for: \$SERVICES"
        docker compose -f compose.prod.yml pull \$SERVICES

        echo "Updating IMAGE_TAG in .env..."
        if grep -q '^IMAGE_TAG=' .env; then
          sed -i 's/^IMAGE_TAG=.*/IMAGE_TAG=$CI_COMMIT_SHORT_SHA/' .env
        else
          echo "IMAGE_TAG=$CI_COMMIT_SHORT_SHA" >> .env
        fi

        echo "Restarting services: \$SERVICES"
        docker compose -f compose.prod.yml up -d \$SERVICES

        echo "Cleaning up unused Docker images and containers"
        docker system prune -af
      EOF
  dependencies:
    - build-dashlab-prod

pages:
  stage: deploy-docs
  image: python:3.11-slim
  script:
    - apt-get update && apt-get install -y git
    - python3 -m pip install --upgrade pip
    - python3 -m pip install sphinx git+https://github.com/bashtage/sphinx-material.git sphinx-tabs myst_parser
    - sphinx-build docs/src/ public/
  variables:
    PYTHONPATH: "$CI_PROJECT_DIR/src"
  artifacts:
    paths:
      - public
  only:
    - main
